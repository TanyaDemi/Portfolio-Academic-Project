# ðŸ“š Data Engineer Portfolio Projects

| â„– | Project | Skills & Tech Stack | Results |
|---|---------|----------------------|---------|
| 1 | [ETL Pipelines and Courier Payments Data Mart](#data-engineering-project-1-etl-pipelines-and-courier-payments-data-mart) | Airflow, Python, PostgreSQL, MongoDB, REST API, SQL, JSON | Automated ETL pipeline from heterogeneous sources â†’ courier payments data mart |
| 2 | [Data Lake Project: Social Network Analytics](#data-engineering-project-2-data-lake-project-social-network-analytics) | PySpark, Airflow, HDFS, Yandex.Cloud Dataproc, Parquet | Built data marts for profiles, geo-activity & friend recommendations |
| 3 | [Analytical Data Warehouse Development](#data-engineering-project-3-analytical-data-warehouse-development) | Airflow, Vertica, SQL, S3, Python | End-to-end DWH pipeline with Data Vault model & business tables |
| 4 | [Streaming Pipeline](#data-engineering-project-4-streaming-pipeline) | Kafka, Spark Structured Streaming, PostgreSQL, Docker | Real-time data pipeline Kafka â†’ Spark â†’ PostgreSQL + Kafka |
| 5 | [Project Deployment & DWH Setup](#data-engineering-project-5-project-deployment-and-data-warehouse-setup-mart) | Yandex Cloud, Kubernetes, Kafka, PostgreSQL | Deployed services, validated DDS/CDM schemas & full data flow |
| 6 | [Final Project â€” Analytical Data Warehouse](#data-engineering-project-6-final-project--analytical-data-warehouse) | Airflow, Docker, PostgreSQL, Vertica, Python, SQL | Full ETL pipeline with financial data marts & incremental loads |

---

## Data Engineering Project â„–1:  
### ETL Pipelines and Courier Payments Data Mart  

**Project Overview**  
This academic project demonstrates the design and implementation of an ETL pipeline using Apache Airflow and Python for data orchestration.  
Data was ingested from multiple sources (PostgreSQL, MongoDB, API), processed through a multi-layered architecture (staging, DDS, CDM), and transformed into a data mart for courier payments.

**Tech Stack**
- Airflow (DAG orchestration)  
- Python (ETL scripts)  
- PostgreSQL (relational data source)  
- MongoDB (NoSQL data source)  
- REST API (external data source)  
- JSON, SQL  
- Snowflake schema, multi-layer DWH  

**Key Deliverables**
- Automated DAGs for ETL workflows  
- Incremental + batch loads  
- Normalized DDS + analytical CDM  
- Data mart for courier payouts  

---

## Data Engineering Project â„–2:  
### Data Lake Project: Social Network Analytics
...
